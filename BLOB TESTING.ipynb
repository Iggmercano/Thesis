{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e94db1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030a4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b9732",
   "metadata": {},
   "source": [
    "# Getting the file paths of json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dad0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        files = glob.glob(os.path.join(root, '*.json'))\n",
    "        for f in files:\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37dda6b",
   "metadata": {},
   "source": [
    "# Storing file path in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae149fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collision Detection Function\n",
    "def has_collision(data):\n",
    "    for pivot in range(data['colonies_number']):\n",
    "        for compare in range(pivot + 1, data['colonies_number']):\n",
    "            c1 = data['labels'][pivot]\n",
    "            c2 = data['labels'][compare]\n",
    "\n",
    "            # Not sure if only using height is ok, upon manual inspection width and height are always equal\n",
    "            r1 = c1['height']/2\n",
    "            r2 = c2['height']/2\n",
    "\n",
    "            # NOTE: x and y (in the JSON file) is the top-left corner of the colony bounding box;\n",
    "            x1 = c1['x'] + c1['width']/2\n",
    "            x2 = c2['x'] + c2['width']/2\n",
    "            y1 = c1['y'] + c1['height']/2\n",
    "            y2 = c2['y'] + c2['height']/2\n",
    "\n",
    "            # Detect if ANY pair of two colonies are colliding\n",
    "            if (r1 + r2 > math.sqrt((x2 - x1)**2 + (y2 - y1)**2)):\n",
    "                # print('Collision: ' + '(' + str(x1) + ', ' + str(y1) + ') (' + str(x2) + ', ' + str(y2) + ')')\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b415d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.path.dirname(\"__file__\")\n",
    "json_file = get_files(os.path.join(dir, 'Sample Set'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388489a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = []\n",
    "for i in json_file:\n",
    "    with open(i, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        if (data['background'] == 'vague'):\n",
    "            # print('Background: ' + data['background'])\n",
    "            # print('Filename: ' + json_file)\n",
    "            cleaned_data.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1278f49b",
   "metadata": {},
   "source": [
    "# Resize the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b4334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImage(img):\n",
    "    CONST_HEIGHT = 1000\n",
    "    return cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e5072",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert the Image to Grayscale\n",
    "The blue channel is used instead of getting the average intensities of each channel because of the fact that difference in intensities between the colonies and the dish itself is more apparent in this channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f26baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBlueChannel(img):\n",
    "    (B, G, R) = cv2.split(img)\n",
    "    \n",
    "    if (DEBUGGING):\n",
    "        plt.subplots(figsize = (10, 10))\n",
    "        plt.title(\"Grayscale Image (Blue Channel)\")\n",
    "        plt.imshow(B, cmap = plt.cm.gray)\n",
    "        plt.show()\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873312b",
   "metadata": {},
   "source": [
    "# Automatic Petri Dish Bounds Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f48a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPetriDish(file_name):\n",
    "    \n",
    "    f = open(\"bounds.json\")\n",
    "    \n",
    "    data = json.load(f)\n",
    "    \n",
    "    bounds = data['bounds']\n",
    "    \n",
    "    for d in bounds:\n",
    "        if (d['file_name'] == os.path.splitext(os.path.basename(file_name))[0]):\n",
    "            return int(d['h']), int(d['k']), int(d['r'])\n",
    "    \n",
    "    return -1, -1, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0d546",
   "metadata": {},
   "source": [
    "# Customized Histogram Equalization within Petri Dish Bounds\n",
    "\n",
    "This special type of HE builds the cumulative histogram using only the pixels within the bounds of the petri dish found through the Circular Hough Transform.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c56918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramEqualization(img, h, k, r):\n",
    "    \n",
    "    img_equalized = img\n",
    "    \n",
    "    # Create a histogram using only the pixels within the petri dish\n",
    "    hist_list = [0] * 256\n",
    "    for i in range(img_equalized.shape[0]):\n",
    "        for j in range(img_equalized.shape[1]):\n",
    "            if ((i - h)**2 + (j - k)**2 < r**2):\n",
    "                hist_list[img_equalized[i][j]] += 1;\n",
    "\n",
    "    hist = np.array(hist_list)\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * float(hist.max()) / cdf.max()\n",
    "    \n",
    "    # Show the CDF and histogram of the image\n",
    "    if (DEBUGGING):\n",
    "        plt.plot(cdf_normalized, color = 'b')\n",
    "        plt.hist(img_equalized.flatten(),256,[0,256], color = 'r')\n",
    "        plt.xlim([0,256])\n",
    "        plt.legend(('Cumulative Distribution Function','Histogram'), loc = 'upper left')\n",
    "        plt.show()\n",
    "    \n",
    "    cdf_m = np.ma.masked_equal(cdf,0)\n",
    "    cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "    cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "\n",
    "    img_equalized = cdf[img_equalized]\n",
    "    \n",
    "    # Show the equalized image'\n",
    "    if (DEBUGGING):\n",
    "        plt.subplots(figsize = (10, 10))\n",
    "        plt.title(\"Histogram Equalization\")\n",
    "        plt.imshow(img_equalized, cmap = plt.cm.gray)\n",
    "        plt.show()\n",
    "    \n",
    "    return img_equalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee9c37",
   "metadata": {},
   "source": [
    "# Non-Local Means Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ac58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(img):\n",
    "    # TODO: Change h-value?\n",
    "    img_denoised = cv2.fastNlMeansDenoising(img, None, h = 31)\n",
    "    \n",
    "    if (DEBUGGING):\n",
    "        plt.subplots(figsize = (10, 10))\n",
    "        plt.title(\"Non-Local Means Denoising\")\n",
    "        plt.imshow(img_denoised, cmap = plt.cm.gray)\n",
    "        plt.show()\n",
    "    \n",
    "    return img_denoised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d194c",
   "metadata": {},
   "source": [
    "# Blob Detection\n",
    "\n",
    "Default Parameters of the SimpleBlobDetector are here: <br> https://github.com/opencv/opencv/blob/4.x/modules/features2d/src/blobdetector.cpp\n",
    "\n",
    "OpenCVs blob detector iteratively binarizes the image from 'minThreshold' to 'maxThreshold' in steps of 'thresholdStep' and then finds the contours in that image. A contour is a group of pixels that have the same or similar values, in this case, they are either groups of black or groups of white pixels formed by the binarization process. The blobs detected may then be filtered to fit certain criteria (see parameters).\n",
    "\n",
    "Notes: \n",
    "1. 'minRepeatability' is the number of times a centroid is must be found between each 'thresholdStep' of binarization to be considered a blob. This centroid also considers 'minDistBetweenBlobs' in that any two centroids that are under this minimum distance is considered as one centroid.\n",
    "2. Inertia Ratio measures the elongatedness of each blob. 0 is a line, 1 is a perfect circle.\n",
    "3. Convexity is the ratio between the area of the blob and the convex hull that encloses the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e8537ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectBlobs(img, file_name, h, k, r, min_repeatability, min_dist, min_inertia_ratio, min_convexity): \n",
    "    img_with_blobs = img\n",
    "\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "    \n",
    "    # TODO: Adjust parameters?\n",
    "    params.minThreshold = 0\n",
    "    params.maxThreshold = 255\n",
    "\n",
    "    params.thresholdStep = 1\n",
    "    params.minRepeatability = min_repeatability\n",
    "    params.minDistBetweenBlobs = min_dist\n",
    "\n",
    "    params.minInertiaRatio = min_inertia_ratio\n",
    "    params.minConvexity = min_convexity\n",
    "    \n",
    "    DETECT = \"TRANSLUCENT\"\n",
    "    \n",
    "    if DETECT == \"OPAQUE\":\n",
    "        params.minArea = 45\n",
    "        params.maxArea = 70\n",
    "    elif DETECT == \"TRANSLUCENT\":\n",
    "        params.minArea = 300\n",
    "        \n",
    "    actual_count = 0\n",
    "    counted = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    detectorobj = cv2.SimpleBlobDetector_create(params)\n",
    "    keypoint_info = detectorobj.detect(img_with_blobs)\n",
    "\n",
    "#   img_with_blobs = cv2.drawKeypoints(img_with_blobs, keypoint_info, np.array([]), (255, 0, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "#     if (True):\n",
    "#         plt.subplots(figsize = (10, 10))\n",
    "#         plt.title(\"Blob Detection\")\n",
    "#         plt.imshow(img_with_blobs, cmap=plt.cm.gray)\n",
    "#         plt.show()\n",
    "    \n",
    "    # \"Number of Colonies: \" + str(len(keypoint_info))\n",
    "    # cv2.imwrite(\"Blob Results/\" + file_name, img_with_blobs)\n",
    "    \n",
    "    f = open(f\"Sample Set/{os.path.splitext(os.path.basename(file_name))[0]}.json\")\n",
    "    data = json.load(f)\n",
    "    \n",
    "    size_threshold = 60\n",
    "    \n",
    "    # Count actual colonies, whether OPAQUE or TRANSLUCENT depending on setting\n",
    "    for colony in data['labels']:\n",
    "        if colony['height'] < size_threshold and DETECT == \"OPAQUE\":\n",
    "            actual_count +=1 \n",
    "        elif colony['height'] >= size_threshold and DETECT == \"TRANSLUCENT\":\n",
    "            actual_count +=1 \n",
    "    \n",
    "    # print(f'ACTUAL COUNT ({DETECT}): {actual_count}')\n",
    "    print(\"\") if False else None\n",
    "    \n",
    "    has_match = []\n",
    "    for keypoint in keypoint_info:\n",
    "        \n",
    "#         # Do not count this circle if it is outside of the petri dish\n",
    "#         if ((keypoint.pt[0] - h)**2 + (keypoint.pt[1] - k)**2 < r**2):\n",
    "#             counted += 1\n",
    "#         else:\n",
    "#             print(\"SKIPPED\")\n",
    "#             continue\n",
    "\n",
    "        counted += 1\n",
    "        print(f\"COUNT #{counted}, ({int(keypoint.pt[0])}, {int(keypoint.pt[1])}, {int(keypoint.size/2)})\", end = \"\") if False else None\n",
    "        \n",
    "        for colony in data['labels']:\n",
    "            if DETECT == \"OPAQUE\" and colony['height'] >= size_threshold:\n",
    "                continue\n",
    "            \n",
    "            if DETECT == \"TRANSLUCENT\" and colony['height'] < size_threshold:\n",
    "                continue\n",
    "            \n",
    "            colony_id = colony['id']\n",
    "            radius = int(colony['height']/2)\n",
    "            x = colony['x'] + radius\n",
    "            y = colony['y'] + radius\n",
    "            \n",
    "            # Remap coordinates based on resizing factor\n",
    "            radius /= 4\n",
    "            x /= 4\n",
    "            y /= 4\n",
    "            \n",
    "            # If the center of the detected colony is within max % of the radius of the actual colony, \n",
    "            # and the radius of the colony is within min % error of the actual radius, \n",
    "            # and there is no match for that colony yet, that is a TRUE POSITIVE\n",
    "            \n",
    "            MAX_RADIUS_DIST = radius*0.5\n",
    "            MIN_RADIUS_ERROR = 0.95\n",
    "            \n",
    "            # RED -> FP\n",
    "            img_with_blobs = cv2.drawKeypoints(img_with_blobs, [keypoint], np.array([]), (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "            \n",
    "            if ((keypoint.pt[0] - x)**2 + (keypoint.pt[1] - y)**2 < MAX_RADIUS_DIST**2):\n",
    "                fr1 = \"{:.2f}\".format(radius)\n",
    "                fr2 = \"{:.2f}\".format(keypoint.size/2)\n",
    "                err = \"{:.2f}\".format(radius - (keypoint.size/2)/(keypoint.size/2))\n",
    "                print (f\" DIST MATCH, R1({fr1}) R2({fr2}) ERR({err})\", end = \"\") if False else None\n",
    "                # BLUE -> FP, distance matched but not size\n",
    "                img_with_blobs = cv2.drawKeypoints(img_with_blobs, [keypoint], np.array([]), (255, 0, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "                # if (abs((radius - (keypoint.size/2))/(keypoint.size/2)) < MIN_RADIUS_ERROR):\n",
    "                if (True):\n",
    "                    print (\" SIZE MATCH\", end = \"\") if False else None\n",
    "                    # YELLOW -> FP, distance and size matched but there is already a circle for that colony\n",
    "                    img_with_blobs = cv2.drawKeypoints(img_with_blobs, [keypoint], np.array([]), (255, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "                    if colony_id not in has_match:\n",
    "                        has_match.append(colony_id)\n",
    "                        print(f\" ({x}, {y}, {radius}) MATCH\", end = \"\") if False else None\n",
    "                        img_with_blobs = cv2.drawKeypoints(img_with_blobs, [keypoint], np.array([]), (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "                        break\n",
    "                   # else:\n",
    "                         # print(f\"{x}({circle[0]}), {y}({circle[1]}), {radius}({circle[2]}) DUPLICATE\")\n",
    "        \n",
    "        print(\"\") if False else None\n",
    "        \n",
    "    if (False):\n",
    "        plt.subplots(figsize = (50, 50))\n",
    "        plt.title(\"Blob Detection\")\n",
    "        plt.imshow(img_with_blobs, cmap=plt.cm.gray)\n",
    "        plt.show()\n",
    "    \n",
    "    tp = len(has_match)\n",
    "    \n",
    "    # FALSE POSITIVE = COUNTED - TRUE POSITIVE\n",
    "    # FALSE NEGATIVE = ACTUAL - COUNTED\n",
    "    fp = counted - tp\n",
    "    \n",
    "    if actual_count < counted:\n",
    "        fn = 0\n",
    "    else:\n",
    "        fn = actual_count - counted\n",
    "    \n",
    "    if (True):\n",
    "        try:\n",
    "            precision = tp/(tp+fp)\n",
    "            prec = \"{:.2%}\".format(precision)\n",
    "        except:\n",
    "            prec = \"0.00%\"\n",
    "            \n",
    "        try:  \n",
    "            recall = tp/(tp+fn)\n",
    "            rec = \"{:.2%}\".format(recall)\n",
    "        except:\n",
    "            recall = \"0.00%\"\n",
    "        \n",
    "        try:\n",
    "            fscore = (2*precision*recall)/(precision+recall)\n",
    "            f1 = \"{:.2%}\".format(fscore)\n",
    "        except:\n",
    "            f1 = \"0.00%\"\n",
    "        \n",
    "        # ID, F, P, R, ACTUAL, COUNTED, TP, FP, FN\n",
    "        # print(f\"{file_name}, {str(f1)}, {str(prec)}, {str(rec)}, {actual_count}, {counted}, {tp}, {fp}, {fn}\")\n",
    "        # cv2.imwrite(f\"OPTIMIZED PARAMETER RESULTS/BLOB {DETECT}/\" + file_name, img_with_blobs)\n",
    "    \n",
    "    return actual_count, counted, tp, fp, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82284734",
   "metadata": {},
   "source": [
    "# Complete Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7758a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countColonies(path, file_name, min_repeatability, min_dist, min_inertia_ratio, min_convexity):\n",
    "    img_orig = cv2.imread(path)\n",
    "    img_resized = resizeImage(img_orig)\n",
    "    img_gray = getBlueChannel(img_resized)\n",
    "    h, k, r = detectPetriDish(file_name)\n",
    "    \n",
    "    if not(h == -1 and k == -1 and r == -1):\n",
    "        img_equalized = histogramEqualization(img_gray, h, k, r)\n",
    "        img_denoised = denoise(img_equalized)\n",
    "\n",
    "        # TODO: Sharpen image?\n",
    "        return detectBlobs(img_denoised, file_name, h, k, r, min_repeatability, min_dist, min_inertia_ratio, min_convexity)\n",
    "\n",
    "    else:\n",
    "        return -1, -1, -1, -1, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8e175",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76c886ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.94%, 90.87%, 64.00%, 556, 565, 317, 248, 53, 2, 2, 0.4, 0.7\n",
      "61.69%, 82.18%, 66.71%, 556, 490, 315, 175, 92, 2, 2, 0.4, 0.8\n",
      "81.63%, 61.53%, 69.18%, 556, 364, 302, 62, 192, 2, 2, 0.4, 0.9\n",
      "58.47%, 85.09%, 65.30%, 556, 500, 308, 192, 84, 2, 2, 0.5, 0.7\n",
      "65.99%, 74.74%, 66.51%, 556, 442, 307, 135, 127, 2, 2, 0.5, 0.8\n",
      "83.85%, 58.45%, 67.81%, 556, 341, 292, 49, 215, 2, 2, 0.5, 0.9\n",
      "65.25%, 71.03%, 63.81%, 556, 415, 284, 131, 151, 2, 2, 0.6, 0.7\n",
      "71.92%, 65.11%, 64.05%, 556, 377, 283, 94, 185, 2, 2, 0.6, 0.8\n",
      "88.30%, 53.00%, 64.88%, 556, 303, 271, 32, 253, 2, 2, 0.6, 0.9\n",
      "69.57%, 53.55%, 57.79%, 556, 335, 247, 88, 225, 2, 2, 0.7, 0.7\n",
      "74.67%, 48.99%, 57.69%, 556, 312, 245, 67, 247, 2, 2, 0.7, 0.8\n",
      "87.48%, 43.93%, 57.32%, 556, 268, 243, 25, 288, 2, 2, 0.7, 0.9\n",
      "53.94%, 90.87%, 64.00%, 556, 565, 317, 248, 53, 2, 3, 0.4, 0.7\n",
      "61.69%, 82.18%, 66.71%, 556, 490, 315, 175, 92, 2, 3, 0.4, 0.8\n",
      "81.63%, 61.53%, 69.18%, 556, 364, 302, 62, 192, 2, 3, 0.4, 0.9\n",
      "58.47%, 85.09%, 65.30%, 556, 500, 308, 192, 84, 2, 3, 0.5, 0.7\n",
      "65.99%, 74.74%, 66.51%, 556, 442, 307, 135, 127, 2, 3, 0.5, 0.8\n",
      "83.85%, 58.45%, 67.81%, 556, 341, 292, 49, 215, 2, 3, 0.5, 0.9\n",
      "65.25%, 71.03%, 63.81%, 556, 415, 284, 131, 151, 2, 3, 0.6, 0.7\n",
      "71.92%, 65.11%, 64.05%, 556, 377, 283, 94, 185, 2, 3, 0.6, 0.8\n",
      "88.30%, 53.00%, 64.88%, 556, 303, 271, 32, 253, 2, 3, 0.6, 0.9\n",
      "69.57%, 53.55%, 57.79%, 556, 335, 247, 88, 225, 2, 3, 0.7, 0.7\n",
      "74.67%, 48.99%, 57.69%, 556, 312, 245, 67, 247, 2, 3, 0.7, 0.8\n",
      "87.48%, 43.93%, 57.32%, 556, 268, 243, 25, 288, 2, 3, 0.7, 0.9\n",
      "57.70%, 84.94%, 64.70%, 556, 509, 308, 201, 81, 3, 2, 0.4, 0.7\n",
      "65.61%, 76.90%, 66.76%, 556, 446, 307, 139, 120, 3, 2, 0.4, 0.8\n",
      "85.52%, 58.07%, 67.79%, 556, 341, 293, 48, 215, 3, 2, 0.4, 0.9\n",
      "63.16%, 77.33%, 65.57%, 556, 451, 300, 151, 120, 3, 2, 0.5, 0.7\n",
      "69.63%, 69.61%, 66.15%, 556, 406, 298, 108, 156, 3, 2, 0.5, 0.8\n",
      "87.69%, 55.45%, 66.57%, 556, 320, 283, 37, 236, 3, 2, 0.5, 0.9\n",
      "69.38%, 65.28%, 62.99%, 556, 380, 276, 104, 183, 3, 2, 0.6, 0.7\n",
      "74.61%, 61.25%, 63.07%, 556, 353, 275, 78, 208, 3, 2, 0.6, 0.8\n",
      "91.49%, 50.94%, 63.94%, 556, 288, 264, 24, 268, 3, 2, 0.6, 0.9\n",
      "72.64%, 49.57%, 56.16%, 556, 306, 237, 69, 251, 3, 2, 0.7, 0.7\n",
      "76.78%, 45.71%, 55.89%, 556, 289, 235, 54, 268, 3, 2, 0.7, 0.8\n",
      "87.85%, 41.85%, 55.64%, 556, 256, 234, 22, 300, 3, 2, 0.7, 0.9\n",
      "57.70%, 84.94%, 64.70%, 556, 509, 308, 201, 81, 3, 3, 0.4, 0.7\n",
      "65.61%, 76.90%, 66.76%, 556, 446, 307, 139, 120, 3, 3, 0.4, 0.8\n",
      "85.52%, 58.07%, 67.79%, 556, 341, 293, 48, 215, 3, 3, 0.4, 0.9\n",
      "63.16%, 77.33%, 65.57%, 556, 451, 300, 151, 120, 3, 3, 0.5, 0.7\n",
      "69.63%, 69.61%, 66.15%, 556, 406, 298, 108, 156, 3, 3, 0.5, 0.8\n",
      "87.69%, 55.45%, 66.57%, 556, 320, 283, 37, 236, 3, 3, 0.5, 0.9\n",
      "69.38%, 65.28%, 62.99%, 556, 380, 276, 104, 183, 3, 3, 0.6, 0.7\n",
      "74.61%, 61.25%, 63.07%, 556, 353, 275, 78, 208, 3, 3, 0.6, 0.8\n",
      "91.49%, 50.94%, 63.94%, 556, 288, 264, 24, 268, 3, 3, 0.6, 0.9\n",
      "72.64%, 49.57%, 56.16%, 556, 306, 237, 69, 251, 3, 3, 0.7, 0.7\n",
      "76.78%, 45.71%, 55.89%, 556, 289, 235, 54, 268, 3, 3, 0.7, 0.8\n",
      "87.85%, 41.85%, 55.64%, 556, 256, 234, 22, 300, 3, 3, 0.7, 0.9\n",
      "60.98%, 80.02%, 65.25%, 556, 471, 302, 169, 105, 4, 2, 0.4, 0.7\n",
      "69.02%, 70.72%, 66.23%, 556, 415, 301, 114, 150, 4, 2, 0.4, 0.8\n",
      "87.15%, 55.52%, 66.62%, 556, 324, 285, 39, 232, 4, 2, 0.4, 0.9\n",
      "65.51%, 72.12%, 64.66%, 556, 421, 291, 130, 145, 4, 2, 0.5, 0.7\n",
      "72.01%, 65.25%, 64.74%, 556, 381, 289, 92, 181, 4, 2, 0.5, 0.8\n",
      "90.16%, 52.07%, 64.50%, 556, 298, 270, 28, 258, 4, 2, 0.5, 0.9\n",
      "71.05%, 61.55%, 61.94%, 556, 359, 268, 91, 202, 4, 2, 0.6, 0.7\n",
      "76.11%, 58.16%, 61.80%, 556, 334, 266, 68, 226, 4, 2, 0.6, 0.8\n",
      "92.19%, 48.54%, 62.13%, 556, 274, 253, 21, 282, 4, 2, 0.6, 0.9\n",
      "75.39%, 44.04%, 54.60%, 556, 284, 229, 55, 273, 4, 2, 0.7, 0.7\n",
      "79.74%, 42.25%, 54.34%, 556, 269, 227, 42, 288, 4, 2, 0.7, 0.8\n",
      "89.69%, 39.06%, 53.48%, 556, 239, 223, 16, 317, 4, 2, 0.7, 0.9\n",
      "60.98%, 80.02%, 65.25%, 556, 471, 302, 169, 105, 4, 3, 0.4, 0.7\n",
      "69.02%, 70.72%, 66.23%, 556, 415, 301, 114, 150, 4, 3, 0.4, 0.8\n",
      "87.15%, 55.52%, 66.62%, 556, 324, 285, 39, 232, 4, 3, 0.4, 0.9\n",
      "65.51%, 72.12%, 64.66%, 556, 421, 291, 130, 145, 4, 3, 0.5, 0.7\n",
      "72.01%, 65.25%, 64.74%, 556, 381, 289, 92, 181, 4, 3, 0.5, 0.8\n",
      "90.16%, 52.07%, 64.50%, 556, 298, 270, 28, 258, 4, 3, 0.5, 0.9\n",
      "71.05%, 61.55%, 61.94%, 556, 359, 268, 91, 202, 4, 3, 0.6, 0.7\n",
      "76.11%, 58.16%, 61.80%, 556, 334, 266, 68, 226, 4, 3, 0.6, 0.8\n",
      "92.19%, 48.54%, 62.13%, 556, 274, 253, 21, 282, 4, 3, 0.6, 0.9\n",
      "75.39%, 44.04%, 54.60%, 556, 284, 229, 55, 273, 4, 3, 0.7, 0.7\n",
      "79.74%, 42.25%, 54.34%, 556, 269, 227, 42, 288, 4, 3, 0.7, 0.8\n",
      "89.69%, 39.06%, 53.48%, 556, 239, 223, 16, 317, 4, 3, 0.7, 0.9\n"
     ]
    }
   ],
   "source": [
    "DEBUGGING = False\n",
    "\n",
    "# MIN_REPEATABILITY_LIST = np.arange(2, 4, 1)\n",
    "# MIN_DIST_LIST = np.arange(2, 4, 1)\n",
    "# MIN_INERTIA_RATIO_LIST = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "# MIN_CONVEXITY_LIST = [0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "\n",
    "MIN_REPEATABILITY_LIST = [2, 3, 4]\n",
    "MIN_DIST_LIST = [2, 3]\n",
    "MIN_INERTIA_RATIO_LIST = [0.4, 0.5, 0.6, 0.7]\n",
    "MIN_CONVEXITY_LIST = [0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "# Iterate through all possible combinations of parameters\n",
    "\n",
    "import itertools\n",
    "for params in itertools.product(MIN_REPEATABILITY_LIST, MIN_DIST_LIST, MIN_INERTIA_RATIO_LIST, MIN_CONVEXITY_LIST):\n",
    "                                \n",
    "    # For each set of parameters, detect colonies in all images\n",
    "    min_repeatability, min_dist, min_inertia, min_convexity = params\n",
    "    \n",
    "    total_actual_count = 0\n",
    "    total_counted = 0\n",
    "    total_tp = 0\n",
    "    total_fp = 0\n",
    "    total_fn = 0\n",
    "    \n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    for file in cleaned_data:\n",
    "        file_name = os.path.splitext(os.path.basename(file))[0] + \".jpg\"\n",
    "        actual_count, counted, tp, fp, fn = countColonies(\"Sample Set/\" + file_name, file_name, min_repeatability, min_dist, min_inertia, min_convexity)\n",
    "\n",
    "        try:\n",
    "            total_precision += tp/(tp+fp)\n",
    "        except:\n",
    "            total_precision += 0\n",
    "        \n",
    "        try:\n",
    "            total_recall += tp/(tp+fn)\n",
    "        except:\n",
    "            total_recall += 0\n",
    "            \n",
    "        try:\n",
    "            total_f1 += (2*(tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "        except:\n",
    "            total_f1 += 0\n",
    "        \n",
    "        total_actual_count += actual_count\n",
    "        total_counted += counted\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        \n",
    "        # break\n",
    "        \n",
    "    try:\n",
    "        # prec_int = total_tp/(total_tp+total_fp)\n",
    "        prec_int = total_precision/30\n",
    "        precision = \"{:.2%}\".format(prec_int)\n",
    "    except:\n",
    "        precision = \"0.00%\"\n",
    "    \n",
    "    try:\n",
    "        # rec_int = total_tp/(total_tp+total_fn)\n",
    "        rec_int = total_recall/30\n",
    "        recall = \"{:.2%}\".format(rec_int)\n",
    "    except:\n",
    "        recall = \"0.00%\"\n",
    "    \n",
    "    try:\n",
    "        # f1 = \"{:.2%}\".format((2*prec_int*rec_int)/(prec_int+rec_int))\n",
    "        f1 = \"{:.2%}\".format(total_f1/30)\n",
    "    except:\n",
    "        f1 = \"0.00%\"\n",
    "\n",
    "    # print(f\"P: {precision} R: {recall} F: {f1}, ACTUAL: {str(total_actual_count)}, COUNT: {str(total_counted)}, TP: {str(total_tp)} FP: {str(total_fp)} FN: {str(total_fn)}, MN_REP: {min_repeatability} MN_DIST: {min_dist} MN_IN: {min_inertia} MN_CNVX: {min_convexity}\")\n",
    "    print(f\"{precision}, {recall}, {f1}, {str(total_actual_count)}, {str(total_counted)}, {str(total_tp)}, {str(total_fp)}, {str(total_fn)}, {min_repeatability}, {min_dist}, {min_inertia}, {min_convexity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
